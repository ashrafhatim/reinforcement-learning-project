{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DiscreteDQNforSpaceLanding.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "n3_gth1xJ5nL",
        "I4JMif8_J-C4",
        "c_xNCqU0ApnA",
        "G3LPc-XLAzLg",
        "18nLQn8OOK6B",
        "-iXo1X05XUO7",
        "VGMKAL-dJEkB",
        "HTnccvcvZedl",
        "98ndoGMPloTz",
        "6IefaN1RYHqV",
        "VOfHda2MKALb",
        "M7rZWnb5HyPF",
        "61_N-AP_GPqo",
        "kGiCFYSMK9hr"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtXuIN_rwYha"
      },
      "source": [
        "# Download dependencies and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vgMhj4Sklls"
      },
      "source": [
        "!pip install gym > /dev/null 2>&1\n",
        "\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsJ53oPAL8Q2",
        "outputId": "8e2a5360-59e1-43d2-e9ea-0f3f6308f8c5"
      },
      "source": [
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (58.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omQ__cG_tc2-",
        "outputId": "a1c03703-793b-4872-bd84-3daf6f7553f3"
      },
      "source": [
        "!pip3 install box2d-py\n",
        "!pip3 install gym[Box_2D]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (2.3.8)\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np5n26L3lF9L"
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torch import optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import clear_output\n",
        "from pathlib import Path\n",
        "\n",
        "import random, os.path, math, glob, csv, base64, itertools, sys\n",
        "from pprint import pprint\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import io\n",
        "from IPython.display import HTML\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from pyvirtualdisplay import Display\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcx9B6ulwrW4"
      },
      "source": [
        "# Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CQgs5JCk2q-"
      },
      "source": [
        "def show_video(directory):\n",
        "  \"\"\"\n",
        "  Visualize the environments.\n",
        "  ---\n",
        "  INPUTS\n",
        "    directory: (str) Ppath for the save directory.\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(directory).glob(\"*.mp4\"):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n",
        "\n",
        "def display_env(env_name = 'LunarLander-v2', savePath = \"./gym-results\"):\n",
        "  \"\"\"\n",
        "  Display one episode of gym environment.\n",
        "  ---\n",
        "  INPUTS\n",
        "    env_name: (str) environment name as prescribed in gym library.\n",
        "    savePath: (str) path to save the video.\n",
        "  \"\"\"\n",
        "  # load env.\n",
        "  env = gym.make(env_name)\n",
        "  # wrap env in order to save our experiment on a file.\n",
        "  env = Monitor(env, savePath, force=True, video_callable=lambda episode: True)\n",
        "\n",
        "  done = False\n",
        "  obs = env.reset()\n",
        "  while not done:\n",
        "      action = env.action_space.sample()\n",
        "      obs, reward, done, info = env.step(action)\n",
        "  env.close()\n",
        "  show_video(savePath)\n",
        "  \n",
        "def fix_seed(seed):\n",
        "  \"\"\"\n",
        "  Fix the ramdom seed.\n",
        "  ---\n",
        "  INPUTS\n",
        "    seed: (int) the random seed.\n",
        "  \"\"\"\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RX8LnNAyXa9"
      },
      "source": [
        "# Basic Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swm3ZRDQksC_",
        "outputId": "885b82d1-cdaa-4a81-c5ff-c26394be2a2c"
      },
      "source": [
        "# prepare the visualisation window\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f4da1ee84d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22VYre9g342M"
      },
      "source": [
        "# fix the seed\n",
        "fix_seed(0)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k1q2D32y9lY",
        "outputId": "c67489ec-623a-4f26-db76-cbdfdb1fb407"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXa7YXvXJO0_"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "t2zGWcFQwQeM",
        "outputId": "a1e95086-0d05-47c2-9026-bf0ea12d714a"
      },
      "source": [
        "display_env(env_name = 'LunarLander-v2', savePath = \"./gym-results\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"gym-results/openaigym.video.1.11311.video000000.mp4\" autoplay \n",
              "                    loop controls style=\"height: 400px;\">\n",
              "                    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmkmlL-ElQkc"
      },
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve('http://www.atarimania.com/roms/Roms.rar','Roms.rar')\n",
        "!pip install unrar\n",
        "!unrar x Roms.rar\n",
        "!mkdir rars\n",
        "!mv HC\\ ROMS.zip   rars\n",
        "!mv ROMS.zip  rars\n",
        "!python -m atari_py.import_roms rars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3_gth1xJ5nL"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM4VjB9nJ9tt"
      },
      "source": [
        "class DQN(nn.Module):\n",
        "  def __init__(self, input_dim, hid1_dim, hid2_dim, n_actions):\n",
        "    super(DQN, self).__init__()\n",
        "    \"\"\"\n",
        "    The DQN network Class.\n",
        "    ---\n",
        "    INPUTS:\n",
        "      input_dim: (int) the state dimensionss.\n",
        "      hid1_dim: (int) the first hidden dimension.\n",
        "      hid2_dim: (int) the second hidden dimension.\n",
        "      n_actions: (int) the action dimensions.\n",
        "    \"\"\"\n",
        "    self.input_dim = input_dim\n",
        "    self.hid1_dim = hid1_dim\n",
        "    self.hid2_dim = hid2_dim\n",
        "    self.n_actions = n_actions\n",
        "    self.net = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, self.hid1_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hid1_dim, self.hid2_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hid2_dim, self.n_actions)\n",
        "        )\n",
        "\n",
        "  def forward(self, state):\n",
        "    return self.net(state.float())"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4JMif8_J-C4"
      },
      "source": [
        "# Replay Buffer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12Hy2ePBKBvy"
      },
      "source": [
        "class ReplayBuffer:\n",
        "  def __init__(self,buffer_size,state_dims):\n",
        "    \"\"\"\n",
        "    The Replay Buffer Class. \n",
        "    First in first out buffer, used as memory.\n",
        "    Divided into 5 different buffers:\n",
        "      1- state_buffer: (numpy.ndarray) the current states buffer.\n",
        "      2- next_state_buffer: (numpy.ndarray) the next states buffer.\n",
        "      3- action_buffer: (numpy.ndarray) the actions buffer.\n",
        "      4- reward_buffer: (numpy.ndarray) the reward buffer.\n",
        "      5- termination_buffer: (numpy.ndarray) the termination buffer. Used to track with end of episods actions.\n",
        "    ---\n",
        "    INPUTS\n",
        "      buffer_size: (int) the buffer max size.\n",
        "      state_dims: (int) the state dimensions.\n",
        "    \"\"\"\n",
        "    self.state_dims = state_dims\n",
        "    self.buffer_size = buffer_size\n",
        "    # counter to keep track of the buffer index\n",
        "    self.counter = 0\n",
        "    # initialise the buffers\n",
        "    self.state_buffer = np.zeros((buffer_size,*self.state_dims), dtype=np.float32)\n",
        "    self.next_state_buffer = np.zeros((buffer_size,*self.state_dims), dtype=np.float32)\n",
        "    self.action_buffer = np.zeros(buffer_size, dtype=np.float32)\n",
        "    self.reward_buffer = np.zeros(buffer_size, dtype=np.float32)\n",
        "    self.termination_buffer = np.zeros(buffer_size, dtype=np.bool)\n",
        "\n",
        "  def push(self, state, action, reward, next_state, done):\n",
        "    \"\"\"\n",
        "    Push state, action, reward, next_state, done into the reply buffer\n",
        "    ---\n",
        "    state, action, reward, next_state, done: (numpy.ndarray) \n",
        "    \"\"\"\n",
        "    # mode buffer_size to reset the index when exceed the max size.\n",
        "    index = self.counter % self.buffer_size\n",
        "    # fill the buffers\n",
        "    self.state_buffer[index] = state\n",
        "    self.next_state_buffer[index] = next_state\n",
        "    self.action_buffer[index] = action\n",
        "    self.reward_buffer[index] = reward\n",
        "    self.termination_buffer[index] = done\n",
        "    # increase the conter\n",
        "    self.counter += 1\n",
        "\n",
        "  def sample(self,batch_size, device):\n",
        "    \"\"\"\n",
        "    Sample batch of inputs.\n",
        "    ---\n",
        "    batch_size: (int) the batch size.\n",
        "    device: (str) the available device.\n",
        "    \"\"\"\n",
        "    filled_buffer = min(self.buffer_size, self.counter)\n",
        "    batch_idx = np.random.choice(filled_buffer, batch_size, replace=False)\n",
        "\n",
        "    # convert to tensor\n",
        "    state = torch.tensor(self.state_buffer[batch_idx]).to(device)\n",
        "    actions = torch.tensor(self.action_buffer[batch_idx]).to(device)\n",
        "    rewards = torch.tensor(self.reward_buffer[batch_idx]).to(device)\n",
        "    next_states = torch.tensor(self.next_state_buffer[batch_idx]).to(device)\n",
        "    terminations = torch.tensor(self.termination_buffer[batch_idx]).to(device)\n",
        "\n",
        "    return state, actions, rewards, next_states, terminations\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.buffer_size"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1psdWOe71dcn"
      },
      "source": [
        "# Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUWVI9eeKByb"
      },
      "source": [
        "class Agent:\n",
        "  def __init__(self, env_name, gamma=0.99, epsilon=1, epsilon_min=0.01, epsilon_decrement=0.001, learning_rate=0.0001, batch_size=128,\n",
        "               n_episodes = 700, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128, path=None, tb_path=None, device = 'cpu', printLog = False ):\n",
        "    \"\"\"\n",
        "    The Agent Clsss.\n",
        "    ---\n",
        "    INPUTS:\n",
        "      env_name: (str) the environment name.\n",
        "      gamma: (float) bellman equation constant.\n",
        "      epsilon: (float) epsilon greedy statring value.\n",
        "      epsilon_min: (float) min epsilon value.\n",
        "      epsilon_decrement: (float) epsilon decrement.\n",
        "      learning_rate: (float) learning rate.\n",
        "      batch_size: (int) batch size.\n",
        "      n_episodes: (int) number of games.\n",
        "      n_steps: (int) max number of steps per episode.\n",
        "      buffer_size: (int) max buffer size.\n",
        "      hid1_dim: (int) first hidden dimension.\n",
        "      hid2_dim: (int) second hidden dimension.\n",
        "      path: (str) path for the saving directory.\n",
        "      tb_path: (str) path for the tensorboard directory.\n",
        "      device: (str) the available device.\n",
        "      printLog: (bool) true to print the log while training.\n",
        "\n",
        "    \"\"\"\n",
        "    self.device = device\n",
        "    self.env_name = env_name\n",
        "    self.env = gym.make(self.env_name)\n",
        "    self.gamma = gamma\n",
        "    self.epsilon = epsilon\n",
        "    self.epsilon_min = epsilon_min\n",
        "    self.epsilon_decrement = epsilon_decrement\n",
        "    self.learning_rate = learning_rate\n",
        "    self.batch_size = batch_size\n",
        "    self.n_episodes = n_episodes\n",
        "    self.n_steps = n_steps\n",
        "    self.buffer_size = buffer_size\n",
        "    self.hid1_dim = hid1_dim\n",
        "    self.hid2_dim = hid2_dim\n",
        "    self.state_dims = self.env.observation_space.shape[0]\n",
        "    self.path = path\n",
        "    self.tb_path = tb_path\n",
        "    self.printLog = printLog\n",
        "    # inialise tensorboard writer\n",
        "    self.sw = SummaryWriter(self.tb_path)\n",
        "    # initialise the buffer\n",
        "    self.buffer = ReplayBuffer(self.buffer_size,[self.state_dims])\n",
        "    # initialise the networks\n",
        "    self.dqn = DQN(self.state_dims, self.hid1_dim, self.hid2_dim, self.env.action_space.n).to(self.device)\n",
        "    self.target_net = DQN(self.state_dims, self.hid1_dim, self.hid2_dim, self.env.action_space.n).to(self.device)\n",
        "    self.target_net.load_state_dict(self.dqn.state_dict())\n",
        "    self.target_net.eval()\n",
        "    # initialise the loss\n",
        "    self.loss_fn = torch.nn.MSELoss()\n",
        "    self.optimizer = torch.optim.Adam(self.dqn.parameters(), lr=self.learning_rate)\n",
        "    # list to save the reward per epoch\n",
        "    self.rewards = [] \n",
        "    self.periodic_reward = 0\n",
        "\n",
        "  def epsilon_greedy_action(self, state, env):\n",
        "    \"\"\"\n",
        "    Epsilon greedy function.\n",
        "    explore or learn depending, depend on epsilon.\n",
        "    ---\n",
        "    INPUT\n",
        "      state: the current state.\n",
        "      env: the environment.\n",
        "    OUTPUT\n",
        "      action: the current action.\n",
        "    \"\"\"\n",
        "    explore = np.random.uniform() < self.epsilon\n",
        "    if explore:\n",
        "      action = env.action_space.sample()\n",
        "    else:\n",
        "      state = torch.tensor([ state ]).to(self.device)\n",
        "      actions = self.dqn.forward(state)\n",
        "      action = torch.argmax(actions).item()\n",
        "    return action\n",
        "    \n",
        "  def step(self, state, env):\n",
        "    \"\"\"\n",
        "    One step of gradient update.\n",
        "    ---\n",
        "    INPUTS\n",
        "      state: the current state.\n",
        "      env: the environment.\n",
        "    OUTPUTS\n",
        "      next_state: next state.\n",
        "      env: the environment.\n",
        "      done: (bool) true if the episode ended.\n",
        "\n",
        "    \"\"\"\n",
        "    # do one env step and add the results to the memory\n",
        "    self.dqn.eval()\n",
        "    action = self.epsilon_greedy_action(state, env)\n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "    self.buffer.push(state,action,reward,next_state,done)\n",
        "    self.dqn.train()\n",
        "    # calculate the accomulated reward per episode\n",
        "    self.periodic_reward += reward\n",
        "\n",
        "    # clear the gradient graph  \n",
        "    self.optimizer.zero_grad()\n",
        "    # sample one batch form the memory\n",
        "    state_batch, action_batch, reward_batch, next_state_batch, termination_batch = self.buffer.sample(self.batch_size, self.device)\n",
        "    state_batch, action_batch, reward_batch, next_state_batch, termination_batch = state_batch, action_batch, reward_batch, next_state_batch, termination_batch\n",
        "    # one step of bellman equation\n",
        "    q_eval = self.dqn(state_batch)[np.arange(self.batch_size),action_batch.long()] \n",
        "    q_next = self.target_net(next_state_batch).detach()\n",
        "    q_next[termination_batch] = 0.0 # for terminal y = r\n",
        "    target = reward_batch + self.gamma * q_next.max(dim=1)[0] \n",
        "    # calculate the loss\n",
        "    loss = self.loss_fn(target,q_eval).to(self.device)\n",
        "    loss.backward()\n",
        "    # update the parameters\n",
        "    self.optimizer.step() \n",
        "\n",
        "    # decrease epsilon or keep the minimum value\n",
        "    if self.epsilon > self.epsilon_min:\n",
        "      self.epsilon = self.epsilon - self.epsilon_decrement\n",
        "    else: \n",
        "      self.epsilon = self.epsilon_min\n",
        "\n",
        "    return next_state, env, done\n",
        "\n",
        "  def episode(self, env):\n",
        "    \"\"\"\n",
        "    One episode. And update the target network.\n",
        "    ---\n",
        "    INPUT\n",
        "      env: the environment.\n",
        "    \"\"\"\n",
        "    # reset the environment\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    step = 0\n",
        "  \n",
        "    while not done and step < self.n_steps:\n",
        "      state, env, done = self.step(state, env)\n",
        "      step += 1\n",
        "\n",
        "    # update the targer network\n",
        "    self.target_net.load_state_dict(self.dqn.state_dict())\n",
        "\n",
        "\n",
        "  def train(self):\n",
        "    \"\"\"\n",
        "    The training function.\n",
        "    \"\"\"\n",
        "    # make sure the size of the memory if larger than the batch size.\n",
        "    state = self.env.reset()\n",
        "    for _ in range(self.batch_size):\n",
        "      self.dqn.eval()\n",
        "      action = self.env.action_space.sample() #self.epsilon_greedy_action(state)\n",
        "      next_state, reward, done, _ = self.env.step(action)\n",
        "      self.buffer.push(state,action,reward,next_state,done)\n",
        "      state = next_state\n",
        "\n",
        "    # training loop\n",
        "    for i in range(self.n_episodes):\n",
        "      save_path = self.path + \"/#\" + str(i)\n",
        "      self.env.reset() #gym.make(self.env_name)\n",
        "      env = self.env\n",
        "      if (i % 100) == 0:\n",
        "        env = Monitor(env, save_path, force=True, video_callable=lambda episode: True)\n",
        "      self.episode(env)\n",
        "      if ((i + 1) % 100 == 0) and self.printLog:\n",
        "        avg_reward = np.mean(self.rewards[-50:])\n",
        "        print('EPISODE ', i+1 , 'reward %.2f' % self.periodic_reward, 'average reward %0.2f'% avg_reward, 'epssilon %0.2f' % self.epsilon)\n",
        "        self.env.close()\n",
        "        ### show_video(save_path)\n",
        "        print()\n",
        "      # update tensor board\n",
        "      self.rewards.append(self.periodic_reward)\n",
        "      self.sw.add_scalar('periodic reward per episode', self.periodic_reward, i)\n",
        "      avg_reward = np.mean(self.rewards[-50:])\n",
        "      self.sw.add_scalar('average reward per episode', avg_reward, i)\n",
        "      self.sw.add_scalar('ebs_history per episode', self.epsilon, i)\n",
        "      self.periodic_reward = 0\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_xNCqU0ApnA"
      },
      "source": [
        "# Acrobot-v1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqA2ZwNbKeNa"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/Acrobot-v1/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rUgBYHTMTUR"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/Acrobot-v1\n",
        "!mkdir /content/drive/MyDrive/Acrobot-v1/log_DQN\n",
        "!mkdir /content/drive/MyDrive/Acrobot-v1/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dttn76xCKD_9"
      },
      "source": [
        "agent1 = Agent(env_name=\"Acrobot-v1\", path=\"/content/drive/MyDrive/Acrobot-v1/log_DQN\", tb_path=\"/content/drive/MyDrive/Acrobot-v1/tb_DQN\")\n",
        "agent1.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3LPc-XLAzLg"
      },
      "source": [
        "# MountainCar-v0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8mciP3pNWMC"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/MountainCar-v0/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37OAgBbuM3Gc"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/MountainCar-v0\n",
        "!mkdir /content/drive/MyDrive/MountainCar-v0/log_DQN\n",
        "!mkdir /content/drive/MyDrive/MountainCar-v0/tb_DQN\n",
        "\n",
        "agent1 = Agent(env_name=\"MountainCar-v0\", path=\"/content/drive/MyDrive/MountainCar-v0/log_DQN\", tb_path=\"/content/drive/MyDrive/MountainCar-v0/tb_DQN\")\n",
        "agent1.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ofCjF_rX2B0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mILN3ueJA4Qv"
      },
      "source": [
        "# Pong-ram-v0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os85ReMsXwAc"
      },
      "source": [
        "!kill 476\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/Pong-ram-v0/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fZ8moOBXwDH"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/Pong-ram-v0\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0/log_DQN\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0/tb_DQN\n",
        "\n",
        "agent1 = Agent(env_name=\"Pong-ram-v0\", path=\"/content/drive/MyDrive/Pong-ram-v0/log_DQN\", tb_path=\"/content/drive/MyDrive/MountainCar-v0/tb_DQN\")\n",
        "agent1.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18nLQn8OOK6B"
      },
      "source": [
        "# pong-ram-v0_exp2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jda8LjTX_Wg"
      },
      "source": [
        "# !rm -r /content/drive/MyDrive/Pong-ram-v0_exp2/tb_DQN/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NY7tAXdOJ8I"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/Pong-ram-v0_exp2/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "_lynWZIDXwFn",
        "outputId": "6b34696e-01bc-46b2-cfab-3d2c8677e163"
      },
      "source": [
        "# !mkdir /content/drive/MyDrive/Pong-ram-v0_exp2\n",
        "# !mkdir /content/drive/MyDrive/Pong-ram-v0_exp2/log_DQN\n",
        "# !mkdir /content/drive/MyDrive/Pong-ram-v0_exp2/tb_DQN\n",
        "\n",
        "agent1 = Agent(env_name=\"Pong-ram-v0\", epsilon_decrement=0.000001, learning_rate=0.0001, \n",
        "               batch_size=128,n_episodes = 1000, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "               path=\"/content/drive/MyDrive/Pong-ram-v0_exp2/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp2/tb_DQN\")\n",
        "agent1.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f73f3043ca14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid1_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid2_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                path=\"/content/drive/MyDrive/Pong-ram-v0_exp2/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp2/tb_DQN\")\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0magent1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-d14fc22f0774>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_callable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mavg_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d14fc22f0774>\u001b[0m in \u001b[0;36mepisode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d14fc22f0774>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mq_next\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtermination_batch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward_batch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mq_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# to be edited -> remove [0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3089\u001b[0m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3090\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iXo1X05XUO7"
      },
      "source": [
        "# pong-ram-v0_exp3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN98b5tPKOHo"
      },
      "source": [
        "# learning rate scheduler, learning_rate=0.0001, 4 actions per step, decrease epsilone after the episode not the step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW9MCxOIXcFY"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/Pong-ram-v0_exp3/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZdDZFB8-z33"
      },
      "source": [
        "# !rm -r /content/drive/MyDrive/Pong-ram-v0_exp3/tb_DQN/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP6VX1W7XeMd"
      },
      "source": [
        "# !mkdir /content/drive/MyDrive/Pong-ram-v0_exp3\n",
        "# !mkdir /content/drive/MyDrive/Pong-ram-v0_exp3/log_DQN\n",
        "# !mkdir /content/drive/MyDrive/Pong-ram-v0_exp3/tb_DQN\n",
        "\n",
        "agent1 = Agent(env_name=\"Pong-ram-v0\", epsilon_decrement=0.0011, learning_rate=0.0001, \n",
        "               batch_size=128,n_episodes = 1000, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "               path=\"/content/drive/MyDrive/Pong-ram-v0_exp3/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp3/tb_DQN\")\n",
        "agent1.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGMKAL-dJEkB"
      },
      "source": [
        "# pong-ram-v0_exp4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03hMnRjoJG0B"
      },
      "source": [
        "# No learnin rate scheduler, learning_rate=0.0005, 1 actions per step, decrease epsilone the step with epsilon_decrement=0.0000005"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dse8GHFNGRS"
      },
      "source": [
        "# !rm -r /content/drive/MyDrive/Pong-ram-v0_exp4/tb_DQN/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZazSw5FJG3N"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/Pong-ram-v0_exp4/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "OPa34EpRJHF8",
        "outputId": "6d497f79-ae73-424e-9a9d-7c2b67a3ec26"
      },
      "source": [
        "# !mkdir /content/drive/MyDrive/Pong-ram-v0_exp4\n",
        "# !mkdir /content/drive/MyDrive/Pong-ram-v0_exp4/log_DQN\n",
        "# !mkdir /content/drive/MyDrive/Pong-ram-v0_exp4/tb_DQN\n",
        "\n",
        "agent1 = Agent(env_name=\"Pong-ram-v0\", epsilon_decrement=0.0000005, learning_rate=0.0005, \n",
        "               batch_size=128,n_episodes = 10000, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "               path=\"/content/drive/MyDrive/Pong-ram-v0_exp4/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp4/tb_DQN\")\n",
        "agent1.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5c3b3f5bcea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid1_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid2_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                path=\"/content/drive/MyDrive/Pong-ram-v0_exp4/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp4/tb_DQN\")\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0magent1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-92b57d9cd8b3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_callable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#(i + 1) % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mavg_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-92b57d9cd8b3>\u001b[0m in \u001b[0;36mepisode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m       \u001b[0;31m# self.scheduler.step()##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-92b57d9cd8b3>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_min\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    116\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTnccvcvZedl"
      },
      "source": [
        "# pong-ram-v0_exp5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvmVfhitJfnC"
      },
      "source": [
        "# No learnin rate scheduler, learning_rate=0.0003, 1 actions per step, decrease epsilone the step with epsilon_decrement=0.0000005"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwAonCJdZjlF"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/Pong-ram-v0_exp5/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "j2HTHebxZjq8",
        "outputId": "bf64eefa-958f-43bb-b86b-5973f51cbdc7"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp5\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp5/log_DQN\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp5/tb_DQN\n",
        "\n",
        "agent1 = Agent(env_name=\"Pong-ram-v0\", epsilon_decrement=0.0000005, learning_rate=0.0003, \n",
        "               batch_size=128,n_episodes = 10000, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "               path=\"/content/drive/MyDrive/Pong-ram-v0_exp5/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp5/tb_DQN\")\n",
        "agent1.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-94a732fe4ac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid1_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid2_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                path=\"/content/drive/MyDrive/Pong-ram-v0_exp5/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp5/tb_DQN\")\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0magent1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-92b57d9cd8b3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_callable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#(i + 1) % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mavg_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-92b57d9cd8b3>\u001b[0m in \u001b[0;36mepisode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m       \u001b[0;31m# self.scheduler.step()##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-92b57d9cd8b3>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mstate_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermination_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mstate_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermination_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermination_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-5857c5c458a3>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mfilled_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_state_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtermination_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z9DBfGmZjsi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98ndoGMPloTz"
      },
      "source": [
        "# pong-ram-v0_exp6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llCsVuu2lrot"
      },
      "source": [
        "# No learnin rate scheduler, learning_rate=0.0001, 1 actions per step, decrease epsilone the step with epsilon_decrement=0.0000005"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ztueKm7lrqx"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/Pong-ram-v0_exp6/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "nMPypDXzlru7",
        "outputId": "e60ccf81-2ee2-4d82-81dd-72773bcaaca9"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp6\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp6/log_DQN\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp6/tb_DQN\n",
        "\n",
        "agent1 = Agent(env_name=\"Pong-ram-v0\", epsilon_decrement=0.0000005, learning_rate=0.0001, \n",
        "               batch_size=128,n_episodes = 10000, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "               path=\"/content/drive/MyDrive/Pong-ram-v0_exp6/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp6/tb_DQN\")\n",
        "agent1.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-ca3da7c4429e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid1_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid2_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                path=\"/content/drive/MyDrive/Pong-ram-v0_exp6/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp6/tb_DQN\")\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0magent1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-92b57d9cd8b3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_callable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#(i + 1) % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mavg_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-92b57d9cd8b3>\u001b[0m in \u001b[0;36mepisode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m       \u001b[0;31m# self.scheduler.step()##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-92b57d9cd8b3>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_greedy_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-92b57d9cd8b3>\u001b[0m in \u001b[0;36mepsilon_greedy_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m       \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IefaN1RYHqV"
      },
      "source": [
        "# pong-ram-v0_exp7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUzTUflxYXiZ"
      },
      "source": [
        "# No learnin rate scheduler, batch_size = 256, learning_rate=0.00001, 1 actions per step, decrease epsilone the step with epsilon_decrement=0.0000005"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kvp_BpGlrxV"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/Pong-ram-v0_exp7/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyyjReMEYPrY"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp7\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp7/log_DQN\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp7/tb_DQN\n",
        "\n",
        "agent1 = Agent(env_name=\"Pong-ram-v0\", epsilon_decrement=0.0000005, learning_rate=0.00001, \n",
        "               batch_size=256,n_episodes = 10000, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "               path=\"/content/drive/MyDrive/Pong-ram-v0_exp7/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp7/tb_DQN\")\n",
        "agent1.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOfHda2MKALb"
      },
      "source": [
        "# pong-ram-v0_exp8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVhnubACKBqT"
      },
      "source": [
        "# No learnin rate scheduler, batch_size = 256, learning_rate=0.000015, 1 actions per step, decrease epsilone the step with epsilon_decrement=1.25e-7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDv35j34KBtU"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/Pong-ram-v0_exp8/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKs5X9wNKBva",
        "outputId": "75bede02-b0dc-4dbe-fe9b-a1122d8e063f"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp8\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp8/log_DQN\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp8/tb_DQN\n",
        "\n",
        "agent1 = Agent(env_name=\"Pong-ram-v0\", epsilon_decrement=1.25e-7, learning_rate=0.000015, \n",
        "               batch_size=256,n_episodes = 10000, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "               path=\"/content/drive/MyDrive/Pong-ram-v0_exp8/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp8/tb_DQN\")\n",
        "agent1.train()\n",
        "\n",
        "torch.save(agent1.state_dict(), \"/content/drive/MyDrive/Pong-ram-v0_exp8\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory /content/drive/MyDrive/Pong-ram-v0_exp8: File exists\n",
            "mkdir: cannot create directory /content/drive/MyDrive/Pong-ram-v0_exp8/log_DQN: File exists\n",
            "mkdir: cannot create directory /content/drive/MyDrive/Pong-ram-v0_exp8/tb_DQN: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXz67OenMQpH"
      },
      "source": [
        "\n",
        "torch.save(agent1.state_dict(), \"/content/drive/MyDrive/Pong-ram-v0_exp8/agent.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leEhivw0KBx4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7rZWnb5HyPF"
      },
      "source": [
        "# pong-ram-v0_exp9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFcnf22vNzex"
      },
      "source": [
        "# !rm -r /content/drive/MyDrive/Pong-ram-v0_exp9/tb_DQN/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yT14nx8JJTk"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp9\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp9/log_DQN\n",
        "!mkdir /content/drive/MyDrive/Pong-ram-v0_exp9/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wye4ZrZrHuQa"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/Pong-ram-v0_exp9/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVstMMLHuyZ"
      },
      "source": [
        "agent1 = Agent(env_name=\"Pong-ram-v0\", epsilon_min=0.02, epsilon_decrement=5e-8, learning_rate=0.000015, \n",
        "               batch_size=256,n_episodes = 30000, n_steps = 10000, buffer_size = 150000, hid1_dim=250, hid2_dim=128,  \n",
        "               path=\"/content/drive/MyDrive/Pong-ram-v0_exp9/log_DQN\", tb_path=\"/content/drive/MyDrive/Pong-ram-v0_exp9/tb_DQN\")\n",
        "agent1.train()\n",
        "\n",
        "torch.save(agent1.state_dict(), \"/content/drive/MyDrive/Pong-ram-v0_exp9\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGiCFYSMK9hr"
      },
      "source": [
        "# LurantLander discrete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaCfZWiCL-rC"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/LunarLander-v2/lr\n",
        "!mkdir /content/drive/MyDrive/LunarLander-v2/lr/0.0001\n",
        "# !mkdir /content/drive/MyDrive/LunarLander-v2/batch\n",
        "# !mkdir /content/drive/MyDrive/LunarLander-v2/lr/#1\n",
        "# !mkdir /content/drive/MyDrive/LunarLander-v2/log_DQN\n",
        "# !mkdir /content/drive/MyDrive/LunarLander-v2/tb_DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1yLrqjFLGuc"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/lr/0.0001\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2JXg6zxLGxP"
      },
      "source": [
        "agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=5e-4 , learning_rate=0.003, \n",
        "               batch_size=64,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "               path=\"\", tb_path=\"/content/drive/MyDrive/LunarLander-v2/lr/0.0001\")\n",
        "agent1.train()\n",
        "\n",
        "torch.save(agent1.state_dict(), \"/content/drive/MyDrive/LunarLander-v2/lr/0.0001\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MirbUMaWgvU8"
      },
      "source": [
        "\n",
        "torch.save(agent1.target_net.state_dict(), \"/content/drive/MyDrive/LunarLander-v2/lr/0.0001\" + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb5vQWIsLGzZ"
      },
      "source": [
        "# !rm -r /content/drive/MyDrive/LunarLander-v2/lr/0.0001/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLZeQW1miXav"
      },
      "source": [
        "# lr = 0.1\n",
        "\n",
        "lr =  0.1\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/lr/\" + str(lr)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/lr/{lr}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=5e-4 , learning_rate=lr, \n",
        "#                batch_size=64,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzxwpSoHiXgb"
      },
      "source": [
        "# lr = 0.01\n",
        "\n",
        "lr =  0.01\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/lr/\" + str(lr)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/lr/{lr}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=5e-4 , learning_rate=lr, \n",
        "#                batch_size=64,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD6NvOcGiXm2"
      },
      "source": [
        "# lr = 0.001\n",
        "\n",
        "lr =  0.001\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/lr/\" + str(lr)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/lr/{lr}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=5e-4 , learning_rate=lr, \n",
        "#                batch_size=64,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BezHsEZQl_DU"
      },
      "source": [
        "# lr = 0.0001\n",
        "\n",
        "lr =  0.0001\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/lr/\" + str(lr)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/lr/{lr}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=5e-4 , learning_rate=lr, \n",
        "#                batch_size=64,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km6tVF3hl_Fv"
      },
      "source": [
        "# lr = 0.00001\n",
        "\n",
        "lr =  0.00001\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/lr/\" + str(lr)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/lr/{lr}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=5e-4 , learning_rate=lr, \n",
        "#                batch_size=64,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UviMcqqwmRqD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCgZKO6PmRsp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc2ZJg-jmRwy"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/LunarLander-v2/bz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayaf1WCtmC_e"
      },
      "source": [
        "# bz = 128\n",
        "\n",
        "bz =  128\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/bz/\" + str(bz)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/bz/{bz}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=5e-4 , learning_rate=0.001, \n",
        "#                batch_size=bz,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW5XYvU7msjV"
      },
      "source": [
        "# bz = 256\n",
        "\n",
        "bz =  256\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/bz/\" + str(bz)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/bz/{bz}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=5e-4 , learning_rate=0.001, \n",
        "#                batch_size=bz,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e41T2K-imsls"
      },
      "source": [
        "# bz = 512\n",
        "\n",
        "bz =  512\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/bz/\" + str(bz)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/bz/{bz}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=5e-4 , learning_rate=0.001, \n",
        "#                batch_size=bz,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW6QcKETmsoJ"
      },
      "source": [
        "# bz = 32\n",
        "\n",
        "bz =  32\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/bz/\" + str(bz)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/bz/{bz}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=5e-4 , learning_rate=0.001, \n",
        "#                batch_size=bz,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzxTcPMAmsqI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h6IfSYfu_yI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru2SYBDUu_1f"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/LunarLander-v2/ed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAYOSwuFvD6q"
      },
      "source": [
        "# ed = 5e-5\n",
        "\n",
        "ed =  5e-5\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/ed/\" + str(ed)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/ed/{ed}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=ed , learning_rate=0.001, \n",
        "#                batch_size=128,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFXN1UNAvb9f"
      },
      "source": [
        "# ed = 5e-6\n",
        "\n",
        "ed =  5e-6\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/ed/\" + str(ed)\n",
        "!mkdir pathd\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/ed/{ed}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=ed , learning_rate=0.001, \n",
        "#                batch_size=128,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAH5VW4yvcAR"
      },
      "source": [
        "# ed = 5e-3\n",
        "\n",
        "ed =  5e-3\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/ed/\" + str(ed)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/ed/{ed}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=ed , learning_rate=0.001, \n",
        "#                batch_size=128,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs51Fwy9vcGF"
      },
      "source": [
        "# ed = 5e-2\n",
        "\n",
        "ed =  5e-2\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/ed/\" + str(ed)\n",
        "!mkdir path\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/ed/{ed}\n",
        "\n",
        "# agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=ed , learning_rate=0.001, \n",
        "#                batch_size=128,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "#                path=\"\", tb_path=path)\n",
        "# agent1.train()\n",
        "\n",
        "# torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5UCJdEwHafC"
      },
      "source": [
        "# !rm -r /content/drive/MyDrive/LunarLander-v2/ed/0.0005/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsbQonsDvnSE"
      },
      "source": [
        "ed = 5e-4\n",
        "\n",
        "ed =  5e-4\n",
        "path = \"/content/drive/MyDrive/LunarLander-v2/ed/\" + str(ed)\n",
        "!mkdir pathd\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/LunarLander-v2/ed/{ed}\n",
        "\n",
        "agent1 = Agent(env_name=\"LunarLander-v2\", epsilon_decrement=ed , learning_rate=0.001, \n",
        "               batch_size=128,n_episodes = 500, n_steps = 5000, buffer_size = 100000, hid1_dim=200, hid2_dim=128,  \n",
        "               path=\"\", tb_path=path)\n",
        "agent1.train()\n",
        "\n",
        "torch.save(agent1.target_net.state_dict(), path + \"/model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nel--iML8jUU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBkIvdj-Pk-Q"
      },
      "source": [
        "# Github "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgpBJzf1PjdM",
        "outputId": "4e163eb7-616b-4995-f7b7-afc332357644"
      },
      "source": [
        "!git clone https://github.com/ashrafhatim/reinforcement-learning-project-.git"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'reinforcement-learning-project-'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 28 (delta 5), reused 26 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhbLleqmQDM6",
        "outputId": "34fe07c2-2f9c-4e8f-a357-264983880c0e"
      },
      "source": [
        "!python /content/reinforcement-learning-project-/src/discrete/main.py --displayEnv True --n-episodes 3 --env-name \"LunarLander-v2\" --path \"../\" --tb-path \"../\" --printLog True"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hey everything is done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yDo8XdNcpYW"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmnMyZOB63c-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}